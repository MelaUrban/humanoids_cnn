{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5caeb5d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import color, io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import MNIST\n",
    "from torchsummary import summary\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset,random_split,SubsetRandomSampler\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed6fb101",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# CLASS TO NORMALIZE OUR DATA\n",
    "##############################################################\n",
    "\n",
    "class Normalization(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean.view(-1, 1, 1)\n",
    "        self.std = std.view(-1, 1, 1)\n",
    "    def __call__(self, sample):\n",
    "        image, label1, label2, label3 = sample['image'],\\\n",
    "        sample['label_age'], sample['label_gender'], sample['label_race']\n",
    "        \n",
    "        return {'image': image,\n",
    "                'label_age': label1,\n",
    "                'label_gender': label2,\n",
    "                'label_race': label3}\n",
    "\n",
    "##############################################################\n",
    "# CLASS FOR DATA HANDLING IN PYTORCH\n",
    "##############################################################\n",
    "\n",
    "class HumanoidData(Dataset):\n",
    "    def __init__(self, image_tensor, annotations_tensor, train=True, transform=None):\n",
    "        \n",
    "        #Leaving only image related columns\n",
    "        self.x =image_tensor.float()\n",
    "        self.y = annotations_tensor.float()\n",
    "        self.device = torch.device('cuda')\n",
    "            \n",
    "        #############################\n",
    "        # TRANSFORMS\n",
    "        #############################\n",
    "        \n",
    "        #Applying transformation\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image=self.x[idx]\n",
    "        labels=self.y[idx]\n",
    "        \n",
    "        return (image,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b2b16d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset/s loaded\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# LOAD TENSORS FROM FILES\n",
    "##############################################################\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "annotations_tensor = torch.load('tensors/humans_monsters_annotation_tensor.pt', map_location=device)\n",
    "plain_image_tensor = torch.load('tensors/humans_monsters_plain_image_tensor.pt', map_location=device)\n",
    "\n",
    "#rgb_tensor = torch.load('tensors/humans_monsters_rgb_image_tensor.pt', map_location=device)\n",
    "#texture_tensor = torch.load('tensors/humans_monsters_texture_image_tensor.pt', map_location=device)\n",
    "\n",
    "##############################################################\n",
    "# CREATE DATA OBJECTS AND PREPARE THEM FOR THE CNN WITH\n",
    "# THE DATA LOADER CLASS\n",
    "##############################################################\n",
    "\n",
    "plain_dataset = HumanoidData(plain_image_tensor, annotations_tensor)\n",
    "                       \n",
    "print(\"Dataset/s loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3355bc35",
   "metadata": {},
   "source": [
    "#### Original Architecture\n",
    "\n",
    "* Input Layer: fixed image of size 200 x 200 x 1\n",
    "* Second Layer: Convolution with 5-pixels square kernel. Output: feature map of size 196 x 196 x 8.\n",
    "\n",
    "* RelU: The tensor is then passed through a ReLU and batch normalization is applied.\n",
    "\n",
    "* Pooling Layer: Max pooling with stride 2 \n",
    "* Convolution Layer: Convolution with 5-pixels square kernel and 16 output channels Output: Tensor of size 94 x 94 x 16.\n",
    "\n",
    "* Pooling Layer: Max pooling with stride 2. And then flatten. Output: tensor of size 35344\n",
    "\n",
    "* Fully Connected Layer:\n",
    "* RelU: The tensor is then passed through a ReLU and batch normalization is applied.\n",
    "\n",
    "* Regressor Layer: Output: 8 human body dimensions in meters\n",
    "\n",
    "#### Training\n",
    "* 20 epochs\n",
    "* mini_batch_size = 100\n",
    "* Loss = MSE\n",
    "* learning_rate = 0.01\n",
    "* momentum = 0.9\n",
    "* TODO: regressor funktion\n",
    "* For layers\n",
    "* \n",
    "* https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ccb649",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# CONVOLUTIONAL NEURAL NETWORK\n",
    "##############################################################\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    '''\n",
    "    Simple Convolutional Neural Network\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "\n",
    "          # input layer 200 x 200 x 1 - (in: 1 color channel, out: 8 Channels, ...)\n",
    "          # output 196 x 196 x 8  \n",
    "          nn.Conv2d(1, 8, kernel_size=5),\n",
    "          nn.ReLU(),\n",
    "            \n",
    "          # batch ormalization layer\n",
    "          nn.LayerNorm((196, 196)),\n",
    "\n",
    "          # input 196 x 196 x 8 \n",
    "          # output 98 x 98 x 8\n",
    "          nn.MaxPool2d(stride=2, kernel_size=1),\n",
    "\n",
    "          # input 98 x 98 x 8\n",
    "          # output 94 x 94 x 16\n",
    "          nn.Conv2d(8, 16, kernel_size=5),\n",
    "          nn.ReLU(),\n",
    "\n",
    "          # input 94 x 94 x 16\n",
    "          # output 47 x 47 x 16\n",
    "          nn.MaxPool2d(stride=2, kernel_size=1),\n",
    "\n",
    "          # Pooling Layer: Max pooling with stride 2. And then flatten.\n",
    "          # Output: tensor of size 35344 = 47 x 47 x 16\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(35344, 512),\n",
    "          nn.ReLU(),\n",
    "\n",
    "          # Last Layer - Regressor\n",
    "          # input 35344\n",
    "          # output 8\n",
    "          nn.Linear(512, 8)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        inputs = x.unsqueeze(1)\n",
    "        outputs = self.layers(inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e51dfc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# TRAIN LOOP\n",
    "##############################################################\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    print(\"Train:\")\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae8c4ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# TEST LOOP\n",
    "##############################################################\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct, diff, diff_fracture = 0, 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(0) == y).type(torch.float).sum().item()\n",
    "            diff += (abs(pred.argmax(0) - y)).type(torch.float).sum().item() #with or without argmax?\n",
    "            diff_fracture += (abs(pred.argmax(0) - y)/y).type(torch.float).sum().item() #with or without argmax?\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    diff /= size\n",
    "    diff_fracture /= size\n",
    "    print(f\"\\nTest Error: \\n AMAD: {(diff):>0.3f}%, \\n ARPE: {(diff_fracture):>0.3f}%, \\n Avg loss: {test_loss:>6f} \\n\")\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "246871f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [1, 8, 196, 196]             208\n",
      "              ReLU-2           [1, 8, 196, 196]               0\n",
      "         LayerNorm-3           [1, 8, 196, 196]          76,832\n",
      "         MaxPool2d-4             [1, 8, 98, 98]               0\n",
      "            Conv2d-5            [1, 16, 94, 94]           3,216\n",
      "              ReLU-6            [1, 16, 94, 94]               0\n",
      "         MaxPool2d-7            [1, 16, 47, 47]               0\n",
      "           Flatten-8                 [1, 35344]               0\n",
      "            Linear-9                   [1, 512]      18,096,640\n",
      "             ReLU-10                   [1, 512]               0\n",
      "           Linear-11                     [1, 8]           4,104\n",
      "================================================================\n",
      "Total params: 18,181,000\n",
      "Trainable params: 18,181,000\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 10.32\n",
      "Params size (MB): 69.36\n",
      "Estimated Total Size (MB): 79.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# HYPER PARAMETERS\n",
    "##############################################################\n",
    "\n",
    "# Loss Function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Model of our Neural Network - push to GPU\n",
    "model = ConvNet().to(device)\n",
    "                     \n",
    "# Use Stochastic Gradient Descent as function to optimize\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "summary(model, (200, 200),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d24d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.901836  [    0/14000]\n",
      "loss: 0.002399  [ 5000/14000]\n",
      "loss: 0.001719  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 68.235%, \n",
      " ARPE: 95.735%, \n",
      " Avg loss: 0.002367 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.005533  [    0/14000]\n",
      "loss: 0.001765  [ 5000/14000]\n",
      "loss: 0.002078  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 84.526%, \n",
      " ARPE: 119.263%, \n",
      " Avg loss: 0.001829 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.001241  [    0/14000]\n",
      "loss: 0.000957  [ 5000/14000]\n",
      "loss: 0.001262  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 93.972%, \n",
      " ARPE: 131.042%, \n",
      " Avg loss: 0.001548 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.001421  [    0/14000]\n",
      "loss: 0.000674  [ 5000/14000]\n",
      "loss: 0.002662  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 68.368%, \n",
      " ARPE: 95.752%, \n",
      " Avg loss: 0.001352 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.001044  [    0/14000]\n",
      "loss: 0.001206  [ 5000/14000]\n",
      "loss: 0.000963  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 80.113%, \n",
      " ARPE: 112.236%, \n",
      " Avg loss: 0.001340 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000734  [    0/14000]\n",
      "loss: 0.001424  [ 5000/14000]\n",
      "loss: 0.001429  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 83.729%, \n",
      " ARPE: 119.504%, \n",
      " Avg loss: 0.001154 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000733  [    0/14000]\n",
      "loss: 0.001061  [ 5000/14000]\n",
      "loss: 0.000621  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 78.310%, \n",
      " ARPE: 111.135%, \n",
      " Avg loss: 0.001259 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000745  [    0/14000]\n",
      "loss: 0.000591  [ 5000/14000]\n",
      "loss: 0.002058  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 77.755%, \n",
      " ARPE: 111.285%, \n",
      " Avg loss: 0.001014 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000713  [    0/14000]\n",
      "loss: 0.001216  [ 5000/14000]\n",
      "loss: 0.003436  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 68.365%, \n",
      " ARPE: 97.335%, \n",
      " Avg loss: 0.001076 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000873  [    0/14000]\n",
      "loss: 0.000986  [ 5000/14000]\n",
      "loss: 0.000612  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 69.712%, \n",
      " ARPE: 100.239%, \n",
      " Avg loss: 0.000954 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.003472  [    0/14000]\n",
      "loss: 0.000499  [ 5000/14000]\n",
      "loss: 0.000715  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 77.791%, \n",
      " ARPE: 110.273%, \n",
      " Avg loss: 0.001062 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000675  [    0/14000]\n",
      "loss: 0.000421  [ 5000/14000]\n",
      "loss: 0.000608  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 75.723%, \n",
      " ARPE: 108.982%, \n",
      " Avg loss: 0.000941 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000721  [    0/14000]\n",
      "loss: 0.000489  [ 5000/14000]\n",
      "loss: 0.000364  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 84.892%, \n",
      " ARPE: 122.382%, \n",
      " Avg loss: 0.000920 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000657  [    0/14000]\n",
      "loss: 0.000658  [ 5000/14000]\n",
      "loss: 0.000314  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 77.521%, \n",
      " ARPE: 110.140%, \n",
      " Avg loss: 0.000911 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000557  [    0/14000]\n",
      "loss: 0.000766  [ 5000/14000]\n",
      "loss: 0.001512  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 77.024%, \n",
      " ARPE: 109.783%, \n",
      " Avg loss: 0.000878 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.001029  [    0/14000]\n",
      "loss: 0.000356  [ 5000/14000]\n",
      "loss: 0.000411  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 68.082%, \n",
      " ARPE: 97.635%, \n",
      " Avg loss: 0.000865 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000941  [    0/14000]\n",
      "loss: 0.000409  [ 5000/14000]\n",
      "loss: 0.000618  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 74.111%, \n",
      " ARPE: 108.376%, \n",
      " Avg loss: 0.000833 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000579  [    0/14000]\n",
      "loss: 0.000408  [ 5000/14000]\n",
      "loss: 0.000376  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 78.766%, \n",
      " ARPE: 111.450%, \n",
      " Avg loss: 0.000861 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000378  [    0/14000]\n",
      "loss: 0.000484  [ 5000/14000]\n",
      "loss: 0.000553  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 72.772%, \n",
      " ARPE: 106.700%, \n",
      " Avg loss: 0.000812 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000336  [    0/14000]\n",
      "loss: 0.000388  [ 5000/14000]\n",
      "loss: 0.000288  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 76.016%, \n",
      " ARPE: 109.543%, \n",
      " Avg loss: 0.000802 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.001285  [    0/14000]\n",
      "loss: 0.000677  [ 5000/14000]\n",
      "loss: 0.000606  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 78.058%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000609 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000704  [    0/14000]\n",
      "loss: 0.000541  [ 5000/14000]\n",
      "loss: 0.000418  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 80.837%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000525 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000542  [    0/14000]\n",
      "loss: 0.000377  [ 5000/14000]\n",
      "loss: 0.001300  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 81.009%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000518 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000333  [    0/14000]\n",
      "loss: 0.000406  [ 5000/14000]\n",
      "loss: 0.000406  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 76.252%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000596 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000478  [    0/14000]\n",
      "loss: 0.000715  [ 5000/14000]\n",
      "loss: 0.000398  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 81.003%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000518 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000609  [    0/14000]\n",
      "loss: 0.000884  [ 5000/14000]\n",
      "loss: 0.000406  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 87.247%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000534 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000345  [    0/14000]\n",
      "loss: 0.000457  [ 5000/14000]\n",
      "loss: 0.000395  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 87.115%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000524 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000483  [    0/14000]\n",
      "loss: 0.000350  [ 5000/14000]\n",
      "loss: 0.000495  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 87.108%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000500 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000372  [    0/14000]\n",
      "loss: 0.000313  [ 5000/14000]\n",
      "loss: 0.000465  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 81.148%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000586 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000478  [    0/14000]\n",
      "loss: 0.000452  [ 5000/14000]\n",
      "loss: 0.000421  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 79.081%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000514 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000887  [    0/14000]\n",
      "loss: 0.000351  [ 5000/14000]\n",
      "loss: 0.000318  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 83.265%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000452 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000467  [    0/14000]\n",
      "loss: 0.000331  [ 5000/14000]\n",
      "loss: 0.001136  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 74.698%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000545 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000410  [    0/14000]\n",
      "loss: 0.000321  [ 5000/14000]\n",
      "loss: 0.000558  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 77.695%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000516 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000690  [    0/14000]\n",
      "loss: 0.000341  [ 5000/14000]\n",
      "loss: 0.000359  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 78.306%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000452 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000288  [    0/14000]\n",
      "loss: 0.000376  [ 5000/14000]\n",
      "loss: 0.001238  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 72.203%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000455 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000270  [    0/14000]\n",
      "loss: 0.000519  [ 5000/14000]\n",
      "loss: 0.000499  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 71.662%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000445 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000202  [    0/14000]\n",
      "loss: 0.000366  [ 5000/14000]\n",
      "loss: 0.001767  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 80.711%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000469 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000693  [    0/14000]\n",
      "loss: 0.000414  [ 5000/14000]\n",
      "loss: 0.000739  [10000/14000]\n",
      "\n",
      "Test Error: \n",
      " AMAD: 73.793%, \n",
      " ARPE: inf%, \n",
      " Avg loss: 0.000468 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train:\n",
      "loss: 0.000280  [    0/14000]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# TRAIN NETWORK \n",
    "##############################################################\n",
    "\n",
    "# Store AVG Loss for plotting\n",
    "avg_losses = []\n",
    "\n",
    "# Train Parameters\n",
    "epochs = 20\n",
    "k=5          # no_folds\n",
    "batch_size = 100\n",
    "\n",
    "# k-fold cross validation - 4 folds test, 1 fold train -> random state for replicable results\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "\n",
    "# k-fold cross validation - 4 folds test, 1 fold train\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(plain_dataset)))):\n",
    "    \n",
    "    # get samples from k fold\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(plain_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    test_loader = DataLoader(plain_dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "    # train epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "        train_loop(train_loader, model, loss_fn, optimizer)\n",
    "        avg_losses.append(test_loop(test_loader, model, loss_fn))\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# PLOTS\n",
    "##############################################################\n",
    "\n",
    "#################################\n",
    "# LOSS FUNCTION\n",
    "#################################\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(avg_losses, linewidth=4)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.ylabel('Avg MSE Loss', fontsize=18)\n",
    "plt.xlabel('Epochs', fontsize=18)\n",
    "plt.grid(which='both', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3661ab3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

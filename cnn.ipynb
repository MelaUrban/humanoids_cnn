{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5caeb5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import color, io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed6fb101",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# CLASS TO NORMALIZE OUR DATA\n",
    "##############################################################\n",
    "\n",
    "class Normalization(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean.view(-1, 1, 1)\n",
    "        self.std = std.view(-1, 1, 1)\n",
    "    def __call__(self, sample):\n",
    "        image, label1, label2, label3 = sample['image'],\\\n",
    "        sample['label_age'], sample['label_gender'], sample['label_race']\n",
    "        \n",
    "        return {'image': image,\n",
    "                'label_age': label1,\n",
    "                'label_gender': label2,\n",
    "                'label_race': label3}\n",
    "\n",
    "##############################################################\n",
    "# CLASS FOR DATA HANDLING IN PYTORCH\n",
    "##############################################################\n",
    "\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, dataset_tensor, train=True, transform=None):\n",
    "        \n",
    "        #Leaving only image related columns\n",
    "        features=dataset_tensor[:,:39999]\n",
    "     \n",
    "        ##########################################################\n",
    "        # Setting labels\n",
    "        ##########################################################\n",
    "       \n",
    "        label_chest_circumference=dataset_tensor[:,40000]\n",
    "        label_height=dataset_tensor[:,40001]\n",
    "        label_inseam=dataset_tensor[:,40002]\n",
    "        label_left_arm_length=dataset_tensor[:,40003]\n",
    "        label_pelvis_circumference=dataset_tensor[:,40004]\n",
    "        label_right_arm_length=dataset_tensor[:,40005]\n",
    "        label_shoulder_width=dataset_tensor[:,40006]\n",
    "        label_waist_circumference=dataset_tensor[:,40007]\n",
    "        \n",
    "        ##########################################################\n",
    "        # splitting the data into train and validation set\n",
    "        ##########################################################\n",
    "        \n",
    "        X_train, X_test, y_chest_circumference_train, y_chest_circumference_test,\\\n",
    "        y_height_train, y_height_test, y_inseam_train, y_inseam_test,\\\n",
    "        y_left_arm_length_train, y_left_arm_length_test,\\\n",
    "        y_pelvis_circumference_train, y_pelvis_circumference_test,\\\n",
    "        y_right_arm_length_train, y_right_arm_length_test,\\\n",
    "        y_shoulder_width_train, y_shoulder_width_test,\\\n",
    "        y_waist_circumference_train, y_waist_circumference_test = train_test_split(features, label_chest_circumference, \n",
    "                           label_height, label_inseam,\n",
    "                           label_left_arm_length, label_pelvis_circumference,\n",
    "                           label_right_arm_length, label_shoulder_width,\n",
    "                           label_waist_circumference, test_size=0.2)\n",
    "        \n",
    "        if train==True:\n",
    "            self.x=X_train\n",
    "            self.chest_circumference_y=y_chest_circumference_train\n",
    "            self.height_y=y_height_train\n",
    "            self.inseam_y=y_inseam_train\n",
    "            self.left_arm_length_y=y_left_arm_length_train\n",
    "            self.pelvis_circumference_y=y_pelvis_circumference_train\n",
    "            self.right_arm_length_y=y_right_arm_length_train\n",
    "            self.shoulder_width_y=y_shoulder_width_train\n",
    "            self.waist_circumference_y=y_waist_circumference_train\n",
    "        else:\n",
    "            self.x=X_test\n",
    "            self.chest_circumference_y=y_chest_circumference_test\n",
    "            self.height_y=y_height_test\n",
    "            self.inseam_y=y_inseam_test\n",
    "            self.left_arm_length_y=y_left_arm_length_test\n",
    "            self.pelvis_circumference_y=y_pelvis_circumference_test\n",
    "            self.right_arm_length_y=y_right_arm_length_test\n",
    "            self.shoulder_width_y=y_shoulder_width_test\n",
    "            self.waist_circumference_y=y_waist_circumference_test \n",
    "            \n",
    "        #############################\n",
    "        # TRANSFORMS\n",
    "        #############################\n",
    "        \n",
    "        # normalize data, w.o. Bessel Correction -> n instead of n-1\n",
    "        std, mean = torch.std_mean(self.x, unbiased=False)\n",
    "        \n",
    "        if transform is None:\n",
    "            intrinsic_transform = torch.nn.Sequential(transforms.Normalize(mean, std))\n",
    "        \n",
    "            #Applying transformation\n",
    "            self.transform=intrinsic_transform\n",
    "        else:\n",
    "            #Applying transformation\n",
    "            self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image=torch.tensor(self.x[idx, 0:])\n",
    "        label1=torch.tensor([self.chest_circumference_y[idx]]).float()\n",
    "        label2=torch.tensor([self.height_y[idx]]).float()\n",
    "        label3=torch.tensor([self.inseam_y[idx]]).float()\n",
    "        label4=torch.tensor([self.left_arm_length_y[idx]]).float()\n",
    "        label5=torch.tensor([self.pelvis_circumference_y[idx]]).float()\n",
    "        label6=torch.tensor([self.right_arm_length_y[idx]]).float()\n",
    "        label7=torch.tensor([self.shoulder_width_y[idx]]).float()\n",
    "        label8=torch.tensor([self.waist_circumference_y[idx]]).float()\n",
    "        labels=torch.cat((label1, label2, label3, label4, label5, label6, label7, label8), -1)\n",
    "        \n",
    "        #Applying transformation\n",
    "        #if self.transform:\n",
    "            #image=self.transform(image)\n",
    "            \n",
    "        return (image,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b2b16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset/s loaded\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# LOAD TENSORS FROM FILES\n",
    "##############################################################\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "plain_tensor = torch.load('tensors/humans_monsters_plain_full_tensor.pt', map_location=device)\n",
    "#rgb_tensor = torch.load('tensors/humans_monsters_rgb_full_tensor.pt', map_location=device)\n",
    "#texture_tensor = torch.load('tensors/humans_monsters_texture_full_tensor.pt', map_location=device)\n",
    "\n",
    "##############################################################\n",
    "# CREATE DATA OBJECTS AND PREPARE THEM FOR THE CNN WITH\n",
    "# THE DATA LOADER CLASS\n",
    "##############################################################\n",
    "\n",
    "plain_dataset_train = MyData(plain_tensor, train=True)\n",
    "plain_dataset_test = MyData(plain_tensor, train=False)\n",
    "\n",
    "#rgb_dataset = MyData(rgb_tensor)\n",
    "#texture_dataset = MyData(texture_tensor)\n",
    "                       \n",
    "test_loader = DataLoader(plain_dataset_test, batch_size=10, num_workers=0)\n",
    "train_loader = DataLoader(plain_dataset_train, batch_size=10, num_workers=0)\n",
    "#loader = DataLoader(plain_dataset, batch_size=10, num_workers=0, shuffle=False)\n",
    "#loader = DataLoader(plain_dataset, batch_size=10, num_workers=0, shuffle=False)\n",
    "                       \n",
    "print(\"Dataset/s loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3355bc35",
   "metadata": {},
   "source": [
    "#### Original Architecture\n",
    "\n",
    "* Input Layer: fixed image of size 200 x 200 x 1\n",
    "* Second Layer: Convolution with 5-pixels square kernel. Output: feature map of size 196 x 196 x 8.\n",
    "\n",
    "* RelU: The tensor is then passed through a ReLU and batch normalization is applied.\n",
    "\n",
    "* Pooling Layer: Max pooling with stride 2 \n",
    "* Convolution Layer: Convolution with 5-pixels square kernel and 16 output channels Output: Tensor of size 94 x 94 x 16.\n",
    "\n",
    "* Pooling Layer: Max pooling with stride 2. And then flatten. Output: tensor of size 35344\n",
    "\n",
    "* Fully Connected Layer:\n",
    "* RelU: The tensor is then passed through a ReLU and batch normalization is applied.\n",
    "\n",
    "* Regressor Layer: Output: 8 human body dimensions in meters\n",
    "\n",
    "#### Training\n",
    "* 20 epochs\n",
    "* mini_batc_size = 100\n",
    "* Loss = MSE\n",
    "* learning_rate = 0.01\n",
    "* momentum = 0.9\n",
    "* TODO: regressor funktion\n",
    "* For layers\n",
    "* \n",
    "* https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ccb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    '''\n",
    "    Simple Convolutional Neural Network\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "\n",
    "          # input layer 200 x 200 x 1 - (in: 1 color channel, out: 8 Channels, ...)\n",
    "          # output 196 x 196 x 8  \n",
    "          nn.Conv2d(1, 8, kernel_size=5),\n",
    "          nn.ReLU(),\n",
    "\n",
    "          # input 196 x 196 x 8 \n",
    "          # output 98 x 98 x 8\n",
    "          nn.MaxPool2d(stride=2, kernel_size=1),\n",
    "\n",
    "          # input 98 x 98 x 8\n",
    "          # output 94 x 94 x 16\n",
    "          nn.Conv2d(8, 16, kernel_size=5),\n",
    "          nn.ReLU(),\n",
    "\n",
    "          # input 94 x 94 x 16\n",
    "          # output 47 x 47 x 16\n",
    "          nn.MaxPool2d(stride=2, kernel_size=1),\n",
    "\n",
    "          # Pooling Layer: Max pooling with stride 2. And then flatten.\n",
    "          # Output: tensor of size 35344 = 47 x 47 x 16\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(35344, 35344),\n",
    "          nn.ReLU(),\n",
    "\n",
    "          # Last Layer - Regressor\n",
    "          # input 35344\n",
    "          # output 8\n",
    "          nn.Linear(35344, 8)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        inputs = x.unsqueeze(0)\n",
    "        outputs = self.layers(inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "075cb9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "model = ConvNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "246871f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e51dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nero\\AppData\\Local\\Temp/ipykernel_21416/362273492.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  image=torch.tensor(self.x[idx, 0:])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [8, 1, 5, 5], but got 3-dimensional input of size [1, 10, 39999] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21416/4045919380.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Make sure gradient tracking is on, and do a pass over the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mavg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# We don't need gradients on to do reporting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21416/2631083443.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(epoch_index, tb_writer)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Make predictions for this batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Compute the loss and its gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21416/2301346544.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 439\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [8, 1, 5, 5], but got 3-dimensional input of size [1, 10, 39999] instead"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(test_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111d677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

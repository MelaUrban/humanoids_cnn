{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caeb5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import color, io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6fb101",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# CLASS TO NORMALIZE OUR DATA\n",
    "##############################################################\n",
    "\n",
    "class Normalization(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean.view(-1, 1, 1)\n",
    "        self.std = std.view(-1, 1, 1)\n",
    "    def __call__(self, sample):\n",
    "        image, label1, label2, label3 = sample['image'],\\\n",
    "        sample['label_age'], sample['label_gender'], sample['label_race']\n",
    "        \n",
    "        return {'image': image,\n",
    "                'label_age': label1,\n",
    "                'label_gender': label2,\n",
    "                'label_race': label3}\n",
    "\n",
    "##############################################################\n",
    "# CLASS FOR DATA HANDLING IN PYTORCH\n",
    "##############################################################\n",
    "\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, image_tensor, annotations_tensor, train=True, transform=None):\n",
    "        \n",
    "        #Leaving only image related columns\n",
    "        features=image_tensor\n",
    "        y = annotations_tensor\n",
    "        device = torch.device('cuda')\n",
    "     \n",
    "        ##########################################################\n",
    "        # Setting labels\n",
    "        ##########################################################\n",
    "       \n",
    "        label_chest_circumference=annotations_tensor[:,0]\n",
    "        label_height=annotations_tensor[:,1]\n",
    "        label_inseam=annotations_tensor[:,2]\n",
    "        label_left_arm_length=annotations_tensor[:,3]\n",
    "        label_pelvis_circumference=annotations_tensor[:,4]\n",
    "        label_right_arm_length=annotations_tensor[:,5]\n",
    "        label_shoulder_width=annotations_tensor[:,6]\n",
    "        label_waist_circumference=annotations_tensor[:,7]\n",
    "        \n",
    "        ##########################################################\n",
    "        # splitting the data into train and validation set\n",
    "        ##########################################################\n",
    "        \n",
    "        X_train, X_test, y_train, y_test= train_test_split(features, y, test_size=0.2)\n",
    "        \n",
    "        if train==True:\n",
    "            self.x=X_train\n",
    "            self.y=y_train\n",
    "        else:\n",
    "            self.x=X_test\n",
    "            self.y=y_test\n",
    "            \n",
    "        #############################\n",
    "        # TRANSFORMS\n",
    "        #############################\n",
    "        \n",
    "        # normalize data, w.o. Bessel Correction -> n instead of n-1\n",
    "        #std, mean = torch.std_mean(self.x.float(), unbiased=False)\n",
    "\n",
    "        #if transform is None:\n",
    "            #intrinsic_transform = torch.nn.Sequential(transforms.Normalize(mean, std))\n",
    "        \n",
    "            #Applying transformation\n",
    "            #self.transform=intrinsic_transform\n",
    "        #else:\n",
    "            #Applying transformation\n",
    "            #self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image=torch.tensor(self.x[idx,:]).float()\n",
    "        labels=torch.tensor(self.y[idx,:]).float()\n",
    "        \n",
    "        #Applying transformation\n",
    "        #if self.transform:\n",
    "            #image=self.transform(image)\n",
    "        return (image,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b2b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# LOAD TENSORS FROM FILES\n",
    "##############################################################\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "annotations_tensor = torch.load('tensors/humans_monsters_annotation_tensor.pt', map_location=device)\n",
    "plain_image_tensor = torch.load('tensors/humans_monsters_plain_image_tensor.pt', map_location=device)\n",
    "\n",
    "print(annotations_tensor[0])\n",
    "print(plain_image_tensor[0])\n",
    "#rgb_tensor = torch.load('tensors/humans_monsters_rgb_image_tensor.pt', map_location=device)\n",
    "#texture_tensor = torch.load('tensors/humans_monsters_texture_image_tensor.pt', map_location=device)\n",
    "\n",
    "##############################################################\n",
    "# CREATE DATA OBJECTS AND PREPARE THEM FOR THE CNN WITH\n",
    "# THE DATA LOADER CLASS\n",
    "##############################################################\n",
    "\n",
    "plain_dataset_train = MyData(plain_image_tensor, annotations_tensor, train=True)\n",
    "plain_dataset_test = MyData(plain_image_tensor, annotations_tensor, train=False)\n",
    "                      \n",
    "test_loader = DataLoader(plain_dataset_test, batch_size=100, num_workers=0)\n",
    "train_loader = DataLoader(plain_dataset_train, batch_size=100, num_workers=0)\n",
    "                       \n",
    "print(\"Dataset/s loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3355bc35",
   "metadata": {},
   "source": [
    "#### Original Architecture\n",
    "\n",
    "* Input Layer: fixed image of size 200 x 200 x 1\n",
    "* Second Layer: Convolution with 5-pixels square kernel. Output: feature map of size 196 x 196 x 8.\n",
    "\n",
    "* RelU: The tensor is then passed through a ReLU and batch normalization is applied.\n",
    "\n",
    "* Pooling Layer: Max pooling with stride 2 \n",
    "* Convolution Layer: Convolution with 5-pixels square kernel and 16 output channels Output: Tensor of size 94 x 94 x 16.\n",
    "\n",
    "* Pooling Layer: Max pooling with stride 2. And then flatten. Output: tensor of size 35344\n",
    "\n",
    "* Fully Connected Layer:\n",
    "* RelU: The tensor is then passed through a ReLU and batch normalization is applied.\n",
    "\n",
    "* Regressor Layer: Output: 8 human body dimensions in meters\n",
    "\n",
    "#### Training\n",
    "* 20 epochs\n",
    "* mini_batc_size = 100\n",
    "* Loss = MSE\n",
    "* learning_rate = 0.01\n",
    "* momentum = 0.9\n",
    "* TODO: regressor funktion\n",
    "* For layers\n",
    "* \n",
    "* https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ccb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    '''\n",
    "    Simple Convolutional Neural Network\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "\n",
    "          # input layer 200 x 200 x 1 - (in: 1 color channel, out: 8 Channels, ...)\n",
    "          # output 196 x 196 x 8  \n",
    "          nn.Conv2d(1, 8, kernel_size=5),\n",
    "          nn.ReLU(),\n",
    "\n",
    "          # input 196 x 196 x 8 \n",
    "          # output 98 x 98 x 8\n",
    "          nn.MaxPool2d(stride=2, kernel_size=1),\n",
    "\n",
    "          # input 98 x 98 x 8\n",
    "          # output 94 x 94 x 16\n",
    "          nn.Conv2d(8, 16, kernel_size=5),\n",
    "          nn.ReLU(),\n",
    "\n",
    "          # input 94 x 94 x 16\n",
    "          # output 47 x 47 x 16\n",
    "          nn.MaxPool2d(stride=2, kernel_size=1),\n",
    "\n",
    "          # Pooling Layer: Max pooling with stride 2. And then flatten.\n",
    "          # Output: tensor of size 35344 = 47 x 47 x 16\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(35344, 35344),\n",
    "          nn.ReLU(),\n",
    "\n",
    "          # Last Layer - Regressor\n",
    "          # input 35344\n",
    "          # output 8\n",
    "          nn.Linear(35344, 8)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        inputs = x.unsqueeze(1)\n",
    "        outputs = self.layers(inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(0) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246871f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "model = ConvNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(test_loader, model, loss_fn, optimizer)\n",
    "    test_loop(train_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111d677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef348a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1bea3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import color, io\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fcf9057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 36000 files into human database\n",
      "loaded 6000 files into monster database\n",
      "loaded 6000 files into all_humans_annotations database\n",
      "pattern_ii_dataset/humans/dataset/annotations\\female/subject_mesh_0001_anno.json\n",
      "loaded 1000 files into all_monsters_annotations database\n",
      "pattern_ii_dataset/monsters/dataset/annotations\\female/subject_mesh_001_anno.json\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# DATA LOADING\n",
    "##############################################################\n",
    "\n",
    "#########################\n",
    "# HUMANS IMAGES\n",
    "#########################\n",
    "\n",
    "\n",
    "humans_path = 'pattern_ii_dataset/humans/dataset/synthetic_images'\n",
    "\n",
    "all_humans = []\n",
    "    \n",
    "for root, dirs, files in sorted(os.walk(humans_path)):\n",
    "    \n",
    "    for name in files:\n",
    "        all_humans.append(str(root) + \"/\" + str(name))\n",
    "        \n",
    "print(\"loaded %d files into human database\" % len(all_humans))\n",
    "\n",
    "#########################\n",
    "# MONSTERS IMAGES\n",
    "#########################\n",
    "\n",
    "monsters_path = 'pattern_ii_dataset/monsters/dataset/synthetic_images'\n",
    "\n",
    "all_monsters = []\n",
    "    \n",
    "for root, dirs, files in sorted(os.walk(monsters_path)):\n",
    "    \n",
    "    for name in files:\n",
    "        all_monsters.append(str(root) + \"/\" + str(name))\n",
    "        \n",
    "print(\"loaded %d files into monster database\" % len(all_monsters))\n",
    "\n",
    "#########################\n",
    "# HUMANS ANNOTATIONS\n",
    "#########################\n",
    "\n",
    "humans_annotations_path = 'pattern_ii_dataset/humans/dataset/annotations'\n",
    "\n",
    "all_humans_annotations = []\n",
    "    \n",
    "for root, dirs, files in sorted(os.walk(humans_annotations_path)):\n",
    "    \n",
    "    for name in files:\n",
    "        all_humans_annotations.append(str(root) + \"/\" + str(name))\n",
    "        \n",
    "print(\"loaded %d files into all_humans_annotations database\" % len(all_humans_annotations))\n",
    "\n",
    "print(all_humans_annotations[0])\n",
    "\n",
    "#########################\n",
    "# MONSTERS ANNOTATIONS\n",
    "#########################\n",
    "\n",
    "monsters_annotations_path = 'pattern_ii_dataset/monsters/dataset/annotations'\n",
    "\n",
    "all_monsters_annotations = []\n",
    "    \n",
    "for root, dirs, files in sorted(os.walk(monsters_annotations_path)):\n",
    "    \n",
    "    for name in files:\n",
    "        all_monsters_annotations.append(str(root) + \"/\" + str(name))\n",
    "        \n",
    "print(\"loaded %d files into all_monsters_annotations database\" % len(all_monsters_annotations))\n",
    "\n",
    "print(all_monsters_annotations[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3ac931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern_ii_dataset/humans/dataset/synthetic_images\\200x200\\pose0\\female/subject_mesh_w_rgb_0001.png\n",
      "pattern_ii_dataset/monsters/dataset/synthetic_images\\200x200\\pose0\\female/subject_mesh_w_rgb_001.png\n",
      "pattern_ii_dataset/humans/dataset/synthetic_images\\200x200\\pose0\\female/subject_mesh_w_texture_0001.png\n",
      "pattern_ii_dataset/monsters/dataset/synthetic_images\\200x200\\pose0\\female/subject_mesh_w_texture_001.png\n",
      "pattern_ii_dataset/humans/dataset/synthetic_images\\200x200\\pose0\\female/subject_mesh_0001.png\n",
      "pattern_ii_dataset/monsters/dataset/synthetic_images\\200x200\\pose0\\female/subject_mesh_001.png\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# DATA SORTING\n",
    "##############################################################\n",
    "\n",
    "##############################\n",
    "# MONSTERS\n",
    "##############################\n",
    "\n",
    "monsters_plain_paths = []\n",
    "monsters_rgb_paths = []\n",
    "monsters_texture_paths = []\n",
    "\n",
    "for monster in all_monsters:\n",
    "    if \"rgb\" in monster:\n",
    "        monsters_rgb_paths.append(monster)\n",
    "    elif \"texture\" in monster:\n",
    "        monsters_texture_paths.append(monster)\n",
    "    else:\n",
    "        monsters_plain_paths.append(monster)\n",
    "\n",
    "##############################\n",
    "# HUMANS\n",
    "##############################\n",
    "\n",
    "humans_plain_paths = []\n",
    "humans_rgb_paths = []\n",
    "humans_texture_paths = []\n",
    "\n",
    "for human in all_humans:\n",
    "    if \"rgb\" in human:\n",
    "        humans_rgb_paths.append(human)\n",
    "    elif \"texture\" in human:\n",
    "        humans_texture_paths.append(human)\n",
    "    else:\n",
    "        humans_plain_paths.append(human)\n",
    "        \n",
    "##############################\n",
    "# ANNOTATIONS\n",
    "##############################\n",
    "\n",
    "\n",
    "monsters_annotations_df = pd.DataFrame() \n",
    "\n",
    "for monster_annotation_path in all_monsters_annotations:\n",
    "    \n",
    "    with open (monster_annotation_path, 'r') as file:\n",
    "    \n",
    "        # load from json\n",
    "        monster_annotation = json.load(file)\n",
    "        sub_df = pd.DataFrame.from_dict(monster_annotation['human_dimensions'], orient='index')\n",
    "        sub_df = sub_df.transpose()\n",
    "        \n",
    "        monsters_annotations_df = monsters_annotations_df.append(sub_df, ignore_index=True)\n",
    "\n",
    "\n",
    "humans_annotations_df = pd.DataFrame() \n",
    "\n",
    "for humans_annotation_path in all_humans_annotations:\n",
    "    \n",
    "    with open (humans_annotation_path, 'r') as file:\n",
    "    \n",
    "        # load from json\n",
    "        human_annotation = json.load(file)\n",
    "        sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "        sub_df = sub_df.transpose()\n",
    "        \n",
    "        humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "    \n",
    "    \n",
    "#print(humans_annotations_df.head())\n",
    "#print(monsters_annotations_df.head())\n",
    "print(humans_rgb_paths[0])    \n",
    "print(monsters_rgb_paths[0])    \n",
    "print(humans_texture_paths[0])    \n",
    "print(monsters_texture_paths[0])    \n",
    "print(humans_plain_paths[0])    \n",
    "print(monsters_plain_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33ca44f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['chest_circumference', 'height', 'inseam', 'left_arm_length',\n",
      "       'pelvis_circumference', 'right_arm_length', 'shoulder_width',\n",
      "       'waist_circumference'],\n",
      "      dtype='object')\n",
      "   chest_circumference    height    inseam  left_arm_length  \\\n",
      "0             1.222634  1.487929  0.514846         0.485513   \n",
      "1             0.897109  1.792233  0.866951         0.628930   \n",
      "2             1.060962  1.509208  0.620023         0.487811   \n",
      "3             1.038552  1.406485  0.550867         0.482332   \n",
      "4             1.141386  1.733648  0.712549         0.602596   \n",
      "\n",
      "   pelvis_circumference  right_arm_length  shoulder_width  waist_circumference  \n",
      "0              1.155255          0.462298        0.389854             1.055119  \n",
      "1              1.058323          0.620611        0.326742             0.756495  \n",
      "2              1.001553          0.475113        0.342354             0.903879  \n",
      "3              0.962185          0.480149        0.367036             0.843582  \n",
      "4              1.259836          0.600523        0.360403             1.053575  \n"
     ]
    }
   ],
   "source": [
    "#print(humans_annotations_df.head())\n",
    "print(humans_annotations_df.columns)\n",
    "print(humans_annotations_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b31344f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# CONVERT IMAGES TO GRAYSCALE\n",
    "##############################################################\n",
    "\n",
    "# reduce number of images for testing purposes\n",
    "n_images = 1000000\n",
    "\n",
    "humans_plain = []\n",
    "humans_texture_grey = []\n",
    "humans_rgb_grey = []\n",
    "monsters_plain = []\n",
    "monsters_texture_grey = []\n",
    "monsters_rgb_grey = []\n",
    "\n",
    "##############################\n",
    "# HUMANS PLAIN\n",
    "##############################\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file_path in humans_plain_paths:\n",
    "    human_plain = io.imread(file_path)\n",
    "    \n",
    "    humans_plain.append(human_plain)\n",
    "       \n",
    "    if i == n_images:\n",
    "        break\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "print(\"1\")\n",
    "##############################\n",
    "# HUMANS W TEXTURE BACKGROUND\n",
    "##############################\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file_path in humans_texture_paths:\n",
    "    human_texture_grey = color.rgb2gray(io.imread(file_path))\n",
    "    \n",
    "    humans_texture_grey.append(human_texture_grey)\n",
    "       \n",
    "    if i == n_images:\n",
    "        break\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "print(\"2\")\n",
    "##############################\n",
    "# HUMANS W RGB BACKGROUND\n",
    "##############################\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file_path in humans_rgb_paths:\n",
    "    human_rgb_grey = color.rgb2gray(io.imread(file_path))\n",
    "    \n",
    "   \n",
    "    humans_rgb_grey.append(human_rgb_grey)\n",
    "       \n",
    "    if i == n_images:\n",
    "        break\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "print(\"3\")\n",
    "##############################\n",
    "# MONSTERS PLAIN\n",
    "##############################\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file_path in monsters_plain_paths:\n",
    "    monster_plain = io.imread(file_path)\n",
    "    \n",
    "    monsters_plain.append(monster_plain)\n",
    "       \n",
    "    if i == n_images:\n",
    "        break\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "print(\"4\")\n",
    "##############################\n",
    "# MONSTERS W TEXTURE BACKGROUND\n",
    "##############################\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file_path in monsters_texture_paths:\n",
    "    monster_texture_grey = color.rgb2gray(io.imread(file_path))\n",
    "      \n",
    "    monsters_texture_grey.append(monster_texture_grey)\n",
    "       \n",
    "    if i == n_images:\n",
    "        break\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "print(\"5\")\n",
    "##############################\n",
    "# MONSTERS W RGB BACKGROUND\n",
    "##############################\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file_path in monsters_rgb_paths:\n",
    "    monster_rgb_grey = color.rgb2gray(io.imread(file_path))\n",
    "    \n",
    "    monsters_rgb_grey.append(monster_rgb_grey)\n",
    "       \n",
    "    if i == n_images:\n",
    "        break\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "print(\"6\")\n",
    "#######################################################################\n",
    "# DISPLAY GREY IMAGES -\n",
    "#######################################################################\n",
    "\n",
    "#cv2.imshow(\"humans_plain\", humans_plain[0])\n",
    "#cv2.imshow(\"humans_rgb_grey\", humans_rgb_grey[0])\n",
    "#cv2.imshow(\"humans_texture_grey\", humans_texture_grey[0])   \n",
    "#cv2.imshow(\"monsters_plain\", monsters_plain[0])     \n",
    "#cv2.imshow(\"monsters_rgb_grey\", monsters_rgb_grey[0])\n",
    "#cv2.imshow(\"monsters_texture_grey\", monsters_texture_grey[5])\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf6a6a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humans_monsters_plain_annotation_tensor.pt saved\n",
      "humans_monsters_plain_image_tensor.pt saved\n",
      "humans_monsters_rgb_image_tensor.pt saved\n",
      "humans_monsters_texture_image_tensor.pt saved\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# CREATE DATA FRAME OF IMAGE VECTORS AND ANNOTATIONS\n",
    "##############################################################\n",
    "\n",
    "##############################\n",
    "# ANNOTATIONS\n",
    "##############################\n",
    "\n",
    "# tensor of annotations\n",
    "humans_annotation_tensor = torch.tensor(humans_annotations_df.values)\n",
    "\n",
    "# copy annotations - pose0 and pose1 have the same annotations\n",
    "humans_annotation_tensor = torch.cat((humans_annotation_tensor,humans_annotation_tensor),0)\n",
    "\n",
    "# tensor of annotations\n",
    "monsters_annotation_tensor = torch.tensor(monsters_annotations_df.values)\n",
    "\n",
    "# copy annotations - pose0 and pose1 have the same annotations\n",
    "monsters_annotation_tensor = torch.cat((monsters_annotation_tensor,monsters_annotation_tensor),0)\n",
    "\n",
    "##############################\n",
    "# HUMAN PLAIN DATA FRAME\n",
    "##############################\n",
    "\n",
    "# tensor of images w.o. annotations\n",
    "humans_plain_image_tensor = torch.tensor(humans_plain)\n",
    "\n",
    "##############################\n",
    "# HUMAN RGB DATA FRAME\n",
    "##############################\n",
    "\n",
    "\n",
    "# tensor of images w.o. annotations\n",
    "humans_rgb_image_tensor = torch.tensor(humans_rgb_grey)\n",
    "\n",
    "##############################\n",
    "# HUMAN TEXTURE DATA FRAME\n",
    "##############################\n",
    "\n",
    "\n",
    "# tensor of images w.o. annotations\n",
    "humans_texture_image_tensor = torch.tensor(humans_texture_grey)\n",
    "\n",
    "##############################\n",
    "# MONSTERS PLAIN DATA FRAME\n",
    "##############################\n",
    "\n",
    "\n",
    "# tensor of images w.o. annotations\n",
    "monsters_plain_image_tensor = torch.tensor(monsters_plain)\n",
    "\n",
    "##############################\n",
    "# MONSTERS RGB DATA FRAME\n",
    "##############################\n",
    "\n",
    "# tensor of images w.o. annotations\n",
    "monsters_rgb_image_tensor = torch.tensor(monsters_rgb_grey)\n",
    "\n",
    "##############################\n",
    "# MONSTERS TEXTURE DATA FRAME\n",
    "##############################\n",
    "\n",
    "# tensor of images w.o. annotations\n",
    "monsters_texture_image_tensor = torch.tensor(monsters_texture_grey)\n",
    "\n",
    "############################################################\n",
    "# COMBINE HUMANS AND MONSTERS AND STORE TENSORS IN FILE\n",
    "############################################################\n",
    "\n",
    "##############################\n",
    "# HUMAN AND MONSTERS PLAIN\n",
    "##############################\n",
    "\n",
    "humans_monsters_annotation_tensor = torch.cat((humans_annotation_tensor, monsters_annotation_tensor),0)\n",
    "humans_monsters_plain_image_tensor = torch.cat((humans_plain_image_tensor, monsters_plain_image_tensor),0)\n",
    "\n",
    "torch.save(humans_monsters_annotation_tensor, 'tensors/humans_monsters_annotation_tensor.pt')\n",
    "print(\"humans_monsters_annotation_tensor.pt saved\")\n",
    "torch.save(humans_monsters_plain_image_tensor, 'tensors/humans_monsters_plain_image_tensor.pt')\n",
    "print(\"humans_monsters_plain_image_tensor.pt saved\")\n",
    "\n",
    "##############################\n",
    "# HUMAN AND MONSTERS RGB\n",
    "##############################\n",
    "\n",
    "humans_monsters_rgb_image_tensor = torch.cat((humans_rgb_image_tensor, monsters_rgb_image_tensor),0)\n",
    "\n",
    "torch.save(humans_monsters_rgb_image_tensor, 'tensors/humans_monsters_rgb_image_tensor.pt')\n",
    "print(\"humans_monsters_rgb_image_tensor.pt saved\")\n",
    "\n",
    "##############################\n",
    "# HUMAN AND MONSTERS TEXTURE\n",
    "##############################\n",
    "\n",
    "humans_monsters_texture_image_tensor = torch.cat((humans_texture_image_tensor, monsters_texture_image_tensor),0)\n",
    "\n",
    "torch.save(humans_monsters_texture_image_tensor, 'tensors/humans_monsters_texture_image_tensor.pt')\n",
    "print(\"humans_monsters_texture_image_tensor.pt saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
